{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bb8af361",
   "metadata": {},
   "source": [
    "## READ ME - Selenium webscraper with Google Chrome\n",
    "\n",
    "This notebook is a set of **Selenium** scripts designed to access specific web portals.\n",
    "\n",
    "Each cell is dedicated to a specific webscrape operation, i.e. a particular webpage. This is because each web portal is set up differently with different types of selection boxes and steps to navigate them.\n",
    "\n",
    "Therefore, each time you use this code for a new webpage, **please copy and paste into a new cell and adapt the script to your use case**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1171d789",
   "metadata": {},
   "source": [
    "## Southampton SOLID services directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "defccf16-1a8a-4071-8307-5f1ac327cd95",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import Select\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "import time\n",
    "import itertools\n",
    "\n",
    "# Set up WebDriver\n",
    "options = webdriver.ChromeOptions()\n",
    "options.add_argument(\"--headless\")  # Run in headless mode (remove for debugging)\n",
    "driver = webdriver.Chrome(service=Service(ChromeDriverManager().install()), options=options)\n",
    "\n",
    "# Open the website\n",
    "url = 'https://solinked.org.uk/location/citywide/?post_types=community_services'\n",
    "driver.get(url)\n",
    "wait = WebDriverWait(driver, 10)\n",
    "\n",
    "# Filters (short)\n",
    "#service_areas = [\n",
    "#    'Access to Food', 'Advice', 'Advice, Information & Guidance',\n",
    "#    'Children & Young People', 'Information & Guidance',\n",
    "#    'Learning Disability and Health Conditions', 'Nature and Animals',\n",
    "#    'Older People', 'Physical Disability, Learning Disability and Health Conditions',\n",
    "#    'Statutory Services'\n",
    "#]\n",
    "# Filters (long)\n",
    "service_areas = [\n",
    "    'Access to Food', 'Advice', 'Advice, Information & Guidance', 'Arts & Heritage & Culture', 'Carers', 'Computer and IT Support',\n",
    "    'Children & Young People', 'Counselling', 'Domestic Abuse','Events', 'Information & Guidance',\n",
    "    'Learning Disability and Health Conditions','LGBTQI+','Mental Health', 'Nature and Animals',\n",
    "    'Older People','Physical Activity','Physical Disability', 'Physical Disability, Learning Disability and Health Conditions','Social Isolation',\n",
    "    'Statutory Services', 'Substance Misuse Support', 'Volunteering & Training'\n",
    "]\n",
    "service_types = [\"Groups & Services\", \"Volunteering\"]\n",
    "locations = [\"Citywide\", \"SO14\", \"SO15\", \"SO16\", \"SO17\", \"SO18\", \"SO19\"]\n",
    "\n",
    "# Data storage\n",
    "data = []\n",
    "\n",
    "# Iterate through all combinations of filters\n",
    "for service_area, service_type, location in itertools.product(service_areas, service_types, locations):\n",
    "    print(f\"\\nüîé Searching for: {service_area} | {service_type} | {location}\")\n",
    "\n",
    "    try:\n",
    "        # Refresh the page before applying new filters\n",
    "        driver.get(url)\n",
    "        time.sleep(5)  # Allow full reload\n",
    "\n",
    "        # Locate dropdowns again after refresh\n",
    "        service_area_dropdown = wait.until(EC.presence_of_element_located((By.ID, \"ofservice_area\")))\n",
    "        service_type_dropdown = wait.until(EC.presence_of_element_located((By.ID, \"ofservice_type\")))\n",
    "        location_dropdown = wait.until(EC.presence_of_element_located((By.ID, \"oflocation\")))\n",
    "\n",
    "        select_service_area = Select(service_area_dropdown)\n",
    "        select_service_type = Select(service_type_dropdown)\n",
    "        select_location = Select(location_dropdown)\n",
    "\n",
    "        # Select filters\n",
    "        select_service_area.select_by_visible_text(service_area)\n",
    "        time.sleep(1)\n",
    "        select_service_type.select_by_visible_text(service_type)\n",
    "        time.sleep(1)\n",
    "        select_location.select_by_visible_text(location)\n",
    "        time.sleep(1)\n",
    "\n",
    "        # Click \"Search\" button\n",
    "        try:\n",
    "            search_button = driver.find_element(By.XPATH, \"//input[@type='submit' and @value='Search']\")\n",
    "            search_button.click()\n",
    "            print(\"‚úÖ Clicked 'Search' button.\")\n",
    "            time.sleep(5)  # Allow time for new results to load\n",
    "        except:\n",
    "            print(\"‚ùå 'Search' button not found!\")\n",
    "\n",
    "        # Scroll down to ensure all results load\n",
    "        last_height = driver.execute_script(\"return document.body.scrollHeight\")\n",
    "        while True:\n",
    "            driver.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")\n",
    "            time.sleep(2)\n",
    "            new_height = driver.execute_script(\"return document.body.scrollHeight\")\n",
    "            if new_height == last_height:\n",
    "                break\n",
    "            last_height = new_height\n",
    "\n",
    "        # Extract services\n",
    "        services = driver.find_elements(By.CSS_SELECTOR, \"article.elementor-post\")\n",
    "\n",
    "        if not services:\n",
    "            print(f\"‚ùå No services found for {service_area} | {service_type} | {location}\")\n",
    "        else:\n",
    "            for service in services:\n",
    "                title_tag = service.find_element(By.CSS_SELECTOR, \"h3.elementor-heading-title a\")\n",
    "                title = title_tag.text.strip()\n",
    "                service_url = title_tag.get_attribute(\"href\")\n",
    "\n",
    "                desc_div = service.find_element(By.CSS_SELECTOR, \"div.elementor-widget-container\")\n",
    "                description = desc_div.text.strip()\n",
    "\n",
    "                data.append([title, description, service_url, f\"{service_area} | {service_type} | {location}\"])\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"üö® Error with filters {service_area} | {service_type} | {location}: {e}\")\n",
    "\n",
    "# Close browser\n",
    "driver.quit()\n",
    "\n",
    "# Convert data to DataFrame\n",
    "df = pd.DataFrame(data, columns=[\"Title\", \"Description\", \"URL\", \"Search Filters\"])\n",
    "\n",
    "# Save to CSV\n",
    "df.to_csv(\"results.csv\", index=False, encoding=\"utf-8\")\n",
    "\n",
    "print(\"\\n‚úÖ Results saved to 'results.csv'!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7971f824",
   "metadata": {},
   "source": [
    "## Living Well Warrington"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5238a5ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚ÑπÔ∏è No cookie banner found.\n",
      "üîÑ Loading all results...\n",
      "‚ûï Clicked 'Load more'\n",
      "‚ûï Clicked 'Load more'\n",
      "‚ûï Clicked 'Load more'\n",
      "‚ûï Clicked 'Load more'\n",
      "‚ûï Clicked 'Load more'\n",
      "‚ûï Clicked 'Load more'\n",
      "‚ûï Clicked 'Load more'\n",
      "‚ûï Clicked 'Load more'\n",
      "‚ûï Clicked 'Load more'\n",
      "‚ûï Clicked 'Load more'\n",
      "‚ûï Clicked 'Load more'\n",
      "‚ûï Clicked 'Load more'\n",
      "‚ûï Clicked 'Load more'\n",
      "‚ûï Clicked 'Load more'\n",
      "‚ûï Clicked 'Load more'\n",
      "‚ûï Clicked 'Load more'\n",
      "‚ûï Clicked 'Load more'\n",
      "‚ûï Clicked 'Load more'\n",
      "‚ûï Clicked 'Load more'\n",
      "‚ûï Clicked 'Load more'\n",
      "‚úÖ No more 'Load more' button. Done loading.\n",
      "üìú Finished scrolling.\n",
      "üìå Found 592 result URLs.\n",
      "‚úÖ Data saved. Found: 592 items.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import Select, WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "import time\n",
    "\n",
    "# Set up WebDriver\n",
    "options = webdriver.ChromeOptions()\n",
    "options.add_argument(\"--headless\")  # Set to False if you want to see the browser\n",
    "driver = webdriver.Chrome(service=Service(ChromeDriverManager().install()), options=options)\n",
    "wait = WebDriverWait(driver, 20)\n",
    "\n",
    "\n",
    "driver.get(\"https://livingwellwarrington.org/activities\")\n",
    "\n",
    "# Try closing cookie banner\n",
    "try:\n",
    "    accept_btn = WebDriverWait(driver, 5).until(\n",
    "        EC.element_to_be_clickable((By.CSS_SELECTOR, \"button[title='Accept All Cookies']\"))\n",
    "    )\n",
    "    accept_btn.click()\n",
    "    print(\"‚úÖ Cookie banner dismissed.\")\n",
    "    time.sleep(2)\n",
    "except:\n",
    "    print(\"‚ÑπÔ∏è No cookie banner found.\")\n",
    "\n",
    "# Scroll to load all results\n",
    "#last_height = driver.execute_script(\"return document.body.scrollHeight\")\n",
    "#while True:\n",
    "#    driver.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")\n",
    "#    time.sleep(3)\n",
    "#    new_height = driver.execute_script(\"return document.body.scrollHeight\")\n",
    "#    if new_height == last_height:\n",
    "#        break\n",
    "#    last_height = new_height\n",
    "\n",
    "#NEW CODE TO TRY AT HOME!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
    "results = driver.find_elements(By.CSS_SELECTOR, \"a.stream__feed__item__title-area__bglink\")\n",
    "\n",
    "from selenium.common.exceptions import TimeoutException, ElementClickInterceptedException, NoSuchElementException\n",
    "\n",
    "print(\"üîÑ Loading all results...\")\n",
    "\n",
    "while True:\n",
    "    try:\n",
    "        load_more_btn = WebDriverWait(driver, 5).until(\n",
    "            EC.element_to_be_clickable((By.CSS_SELECTOR, \"button[wire\\\\:click='loadMore']\"))\n",
    "        )\n",
    "        driver.execute_script(\"arguments[0].scrollIntoView({block: 'center'});\", load_more_btn)\n",
    "        time.sleep(1)\n",
    "        driver.execute_script(\"arguments[0].click();\", load_more_btn)\n",
    "        print(\"‚ûï Clicked 'Load more'\")\n",
    "        time.sleep(2)  # Wait for new content to load\n",
    "    except (TimeoutException, NoSuchElementException):\n",
    "        print(\"‚úÖ No more 'Load more' button. Done loading.\")\n",
    "        break\n",
    "    except ElementClickInterceptedException as e:\n",
    "        print(\"‚ö†Ô∏è Element click intercepted. Trying to scroll more.\")\n",
    "        driver.execute_script(\"window.scrollBy(0, 300);\")\n",
    "        time.sleep(1)\n",
    "\n",
    "print(\"üìú Finished scrolling.\")\n",
    "\n",
    "# Find result links\n",
    "results = driver.find_elements(By.CSS_SELECTOR, \"a.stream__feed__item__title-area__bglink\")\n",
    "urls = [r.get_attribute(\"href\") for r in results]\n",
    "print(f\"üìå Found {len(urls)} result URLs.\")\n",
    "\n",
    "# Extract data from each URL\n",
    "data = []\n",
    "\n",
    "for url in urls:\n",
    "    driver.get(url)\n",
    "    time.sleep(3)\n",
    "\n",
    "    try:\n",
    "        title = driver.find_element(By.CSS_SELECTOR, \"#main > div > div.margin-bottom.activity_page > div.margin-bottom.activity_page__heading > h1\").text.strip()\n",
    "    except:\n",
    "        title = \"\"\n",
    "\n",
    "    try:\n",
    "        content = driver.find_element(By.CSS_SELECTOR, \"#main > div > div.margin-bottom.activity_page > div.margin-bottom.activity_page__content > div.page-content.contains_vid\").text.strip()\n",
    "    except:\n",
    "        content = \"\"\n",
    "\n",
    "    try:\n",
    "        location = driver.find_element(By.CSS_SELECTOR, \"#main > div > div.margin-bottom.activity_page > div.activity_page__imageandinfo > div.margin-bottom.activity_page__imageandinfo__info > div:nth-child(3) > div.activity_page__imageandinfo__info__row__details\").text.strip()\n",
    "    except:\n",
    "        location = \"\"\n",
    "\n",
    "    try:\n",
    "        neighbourhoods = driver.find_elements(By.CSS_SELECTOR, \"#main > div > div.margin-bottom.activity_page > div.activity_page__imageandinfo > div.margin-bottom.activity_page__imageandinfo__info > div:nth-child(4) > div.activity_page__imageandinfo__info__row__details > span > ul > li\")\n",
    "        neighbourhoods_text = \", \".join([n.text.strip() for n in neighbourhoods])\n",
    "    except:\n",
    "        neighbourhoods_text = \"\"\n",
    "\n",
    "    data.append({\n",
    "        \"Title\": title,\n",
    "        \"URL\": url,\n",
    "        \"Page Content\": content,\n",
    "        \"Location\": location,\n",
    "        \"Neighbourhoods\": neighbourhoods_text\n",
    "    })\n",
    "\n",
    "# Save to CSV\n",
    "df = pd.DataFrame(data)\n",
    "df.to_csv(\"livingwellwarrington_results.csv\", index=False, encoding=\"utf-8\")\n",
    "print(\"‚úÖ Data saved. Found:\", len(df), \"items.\")\n",
    "\n",
    "driver.quit()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
